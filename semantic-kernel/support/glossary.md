---
title: Glossary for Semantic Kernel
description: Glossary for Semantic Kernel
author: sophialagerkranspandey
ms.topic: conceptual
ms.author: sopand
ms.date: 02/07/2023
ms.service: semantic-kernel 
---
# Glossary for Semantic Kernel

ðŸ‘‹ Hello! We've included a Glossary below with key terminology. 

| Term/Word | Defintion |
|---|---|
| Agent | An agent is an artificial intelligence that can answer questions and automate processes for users. There's a wide spectrum of agents that can be built, ranging from simple chat bots to fully automated AI assistants. With Semantic Kernel, we provide you with the tools to build increasingly more sophisticated agents that don't require you to be an AI expert. |
| API | Application Programming Interface. A set of rules and specifications that allow software components to communicate and exchange data. |
| Autonomous | Agents that can respond to stimuli with minimal human intervention. | 
| Chatbot | A simple back-and-forth chat with a user and AI Agent.|
| Connectors | Connectors allow you to integrate existing APIs (Application Programming Interface) with LLMs (Large Language Models). For example, a Microsoft Graph connector can be used to automatically send the output of a request in an email, or to build a description of relationships in an organization chart. |
| Copilot | Agents that work side-by-side with a user to complete a task. |
| Kernel | Similar to operating system, the kernel is responsible for managing resources that are necessary to run "code" in an AI application. This includes managing the AI models, services, and plugins that are necessary for both native code and AI services to run together. Because the kernel has all the services and plugins necessary to run both native code and AI services, it is used by nearly every component within the Semantic Kernel SDK. This means that if you run any prompt or code in Semantic Kernel, it will always go through a kernel. |
| LLM | Large Language Models are Artificial Intelligence tools that can summarize, read or generate text in the form of sentences similar to how a humans talk and write. LLMs can be incorporate into various products at Microsoft to unearth richer user value. |
| Memory | Memories are a powerful way to provide broader context for your ask. Historically, we've always called upon memory as a core component for how computers work: think the RAM in your laptop. For with just a CPU that can crunch numbers, the computer isn't that useful unless it knows what numbers you care about. Memories are what make computation relevant to the task at hand. |
| Plugins | To generate this plan, the copilot would first need the capabilities necessary to perform these steps. This is where plugins come in. Plugins allow you to give your agent skills via code. For example, you could create a plugin that sends emails, retrieves information from a database, asks for help, or even saves and retrieves memories from previous conversations. |
| Planners | To use a plugin (and to wire them up with other steps), the copilot would need to first generate a plan. This is where planners come in. Planners are special prompts that allow an agent to generate a plan to complete a task. The simplest planners are just a single prompt that helps the agent use function calling to complete a task. |
| Prompts | Prompts play a crucial role in communicating and directing the behavior of Large Language Models (LLMs) AI. They serve as inputs or queries that users can provide to elicit specific responses from a model. |
| Prompt Engineering | Because of the amount of control that exists, prompt engineering is a critical skill for anyone working with LLM AI models. It's also a skill that's in high demand as more organizations adopt LLM AI models to automate tasks and improve productivity. A good prompt engineer can help organizations get the most out of their LLM AI models by designing prompts that produce the desired outputs. |
| RAG | Retrieval Augmented Generation - a term that refers to the process of retrieving additional data to provide as context to an LLM to use when generating a response (completion) to a userâ€™s question (prompt). |

## More support information

* [Frequently Asked Questions (FAQs)](/semantic-kernel/support/faqs)
* [Hackathon Materials](/semantic-kernel/support/hackathon) 
* [Code of Conduct](/semantic-kernel/support/CodeofConduct)

